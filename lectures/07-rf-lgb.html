
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7. Random Forest, GBM &#8212; 단국대 2020 캐글 뽀개기</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "kaggler-tv/dku-kaggle-class");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Random Forest 실습" href="07-rf.html" />
    <link rel="prev" title="7. Random Forest, GBM" href="07-rf-lgb-intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">단국대 2020 캐글 뽀개기</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../main.html">
   단국대 2020년 가을학기 캐글 뽀개기 강좌
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01-intro.html">
   1장. Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02-setup.html">
   2장. Setup
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="03-pandas-intro.html">
   3장. Pandas
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="03-pandas.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03-pandas-eda.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="04-numpy-intro.html">
   4장. Numpy, 선형회귀, 로지스틱회귀
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="04-numpy.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-numpy-lr.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="05-numerical-features-intro.html">
   5장. 수치형변수 가공
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="05-numerical-features.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="06-scikit-learn-intro.html">
   6장. Scikit-learn, 결정트리
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="06-scikit-learn.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06-decision-trees.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="07-rf-lgb-intro.html">
   7장. Random Forest, GBM
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07-rf.html">
     Random Forest 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07-lightgbm.html">
     LightGBM 실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="08-cv-stacking-intro.html">
   8장. Cross-Validation, Stacking
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="08-cv-stacking.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-lr-cv.html">
     로지스틱 회귀 CV 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-rf-cv.html">
     Random Forest CV 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-lightgbm-cv.html">
     LightGBM CV 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-stacking-lr.html">
     로지스틱 회귀 스태킹 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-stacking-lgb.html">
     LightGBM 스태킹 실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="09-tuning-intro.html">
   9장. 모델 튜닝, Hyperopt, Optuna
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="09-tuning.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-lightgbm-hyperopt.html">
     Hyperopt 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-lightgbm-optuna.html">
     Optuna 실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="10-pipeline-make-intro.html">
   10장. Pipeline, Make
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="10-pipeline-make.html">
     이론
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="11-categorical-features-intro.html">
   11장. 범주형변수 가공
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="11-categorical-features.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="12-nn-intro.html">
   12장. 신경망, Keras
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="12-nn-keras.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12-nn-cv.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="13-text-features-intro.html">
   13장. 문자열변수 가공
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="13-text-features.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13-lr-tfidf.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="14-embeddings-intro.html">
   14장. Embedding, RNN
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="14-embeddings.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14-cnn-emb.html">
     CNN - Embeddings 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14-lstm-emb.html">
     LSTM - Embeddings 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14-lstm-glove.html">
     LSTM - GloVe 실습
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14-attention.html">
     Attention 실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="15-transfer-learning-intro.html">
   15장. 선학습 임베딩, 전이학습
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="15-transfer-learning.html">
     이론
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15-bert.html">
     실습
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16-data-augmentation.html">
   16장. Data Augmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17-cnn.html">
   17장. CNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18-image-classification.html">
   18장. Image Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19-post-processing.html">
   19장. 후처리, 기타팁
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lectures/07-rf-lgb.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/kaggler-tv/dku-kaggle-class/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/kaggler-tv/dku-kaggle-class//issues/new?title=Issue%20on%20page%20%2Flectures/07-rf-lgb.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-forest">
   7.1 Random Forest
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-boosting-machine-gbm">
   7.2 Gradient Boosting Machine (GBM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#xgboost-vs-lightgbm">
   7.3 XGBoost vs LightGBM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   7.4 참고자료
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="random-forest-gbm">
<h1>7. Random Forest, GBM<a class="headerlink" href="#random-forest-gbm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="random-forest">
<h2>7.1 Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this headline">¶</a></h2>
<p>Random Forest는 2010년 초반까지 가장 많이 사용된 결정트리 기반 앙상블 알고리즘입니다. 앙상블 알고리즘은 기본 모델을 여러개 사용해 예측할 때 사용하는 방법입니다. Random Forest는 결정트리 알고리즘을 여러개 활용해 구축한 알고리즘입니다.</p>
<p>1995년에 벨랩에 Tin Kam Ho 박사가 Random Decision Forests라는 논문을 발표하게 됩니다. 이 당시 발표한 내용은 여러개의 결정트리를 랜덤하게 고른 피쳐로 학습한 후 조합하는 방법이였습니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img01.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-1 Tin Kam Ho 박사(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>그리고 2001년에 UC Berkeley의 Leo Breiman 교수가 Tin Kam Ho가 제시한 아이디어에 랜덤 샘플링을 추가해서 Random Forests라는 논문을 발표하게 됩니다. 해당 논문에서는 여러개의 결정트리를 랜덤하게 추출한 피쳐 뿐만 아니라 샘플링도 랜덤하게 해서 학습 후 조합을 실시합니다. 이 방법을 bagging이라고 합니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img02.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-2 Leo Breiman 교수(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>결정트리의 단점으로 과적합이 쉽게 일어나고 variance가 높은 것으로 알려져 있는데 random forest는 variance를 효과적으로 감소시켜준다는 장점이 있습니다.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>머신러닝 모델의 성능 또는 에러에 대해 평가할 때 bias와 variance를 주로 언급합니다. Bias가 높다라는 것은 예측값이 원래 값과 차이가 많이 나는 경우를 의미하며 variance가 높다는 것은 모델을 여러번 학습해서 예측할 때 나온 값의 범위가 큰 경우를 의미합니다.</p>
</div>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img03.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-3 Random forest 알고리즘(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>Random forest를 도식화하면 그림 7-3과 같습니다. 각각의 결정 트리를 다른 피쳐와 다른 샘플로 학습을 합니다. 예를 들어 Tree 1은 첫번째 부터 천번째 샘플의 두번째, 세번째, 네번째 피쳐로 학습을 시키고 Tree 2는 천번째 부터 2천번째 샘플의 첫번째, 두번째, 네번째 피쳐로 학습하고 Tree 3는 2천번째 부터 3천번째의 첫번째, 두번째, 세번째 피쳐로 학습을 시킵니다. 그리고 나서 각 Tree가 예측한 결과를 평균을 내어 최종 예측값을 산출합니다. 그림 7-3에서 처럼 확률 값을 평균 내어 최종 산출 값으로 결정하는 방법을 soft-voting이라고 합니다. Leo Breiman이 발표한 논문에서는 각각의 Tree가 범주를 예측해서 가장 많이 나온 범주를 최종 예측값으로 결정하는 hard-voting방법을 소개했었습니다. 그림 7-3에서는 이진분류를 예시로 들었지만 multi-class 문제에서도 random forest 사용이 가능합니다.</p>
<p>Random forest를 구현하는 코드는 아래와 같습니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img04.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-4 Random forest 사용 예제(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>학습 시 사용하는 주요 인자들에 대한 설망은 아래와 같습니다.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>인자</p></th>
<th class="head"><p>설명</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>n_estimators</p></td>
<td><p>사용할 결정트리의 개수</p></td>
</tr>
<tr class="row-odd"><td><p>min_sample_leaf</p></td>
<td><p>가장 마지막 노드에 존재해야 하는 샘플의 최소 개수</p></td>
</tr>
<tr class="row-even"><td><p>max_features</p></td>
<td><p>결정트리 학습 시 사용할 피쳐 개수, auto일 시 원래 피쳐 개수에 루트(root)를 씌운 값 사용</p></td>
</tr>
<tr class="row-odd"><td><p>max_samples</p></td>
<td><p>샘플할 데이터의 개수</p></td>
</tr>
<tr class="row-even"><td><p>random_state</p></td>
<td><p>재현성을 위한 시드값</p></td>
</tr>
<tr class="row-odd"><td><p>n_jobs</p></td>
<td><p>학습시 사용할 쓰레드의 개수, -1일 경우 사용가능한 모든 쓰레드 사용해 학습</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>표 7-1 Random forest 주요 인자</p></li>
</ul>
<p>주요 인자를 설정해서 Random forest 객체를 생성한 뒤 학습과 예측하는 과정은 scikit-learn에서 제공하는 다른 알고리즘과 마찬가지로 <code class="docutils literal notranslate"><span class="pre">fit()</span></code>과 <code class="docutils literal notranslate"><span class="pre">predict()</span></code>을 사용합니다. <a class="reference internal" href="07-rf.html"><span class="doc std std-doc">실습 파일</span></a>을 통해 random forest를 학습을 실습해보시길 바랍니다.</p>
<p>결정트리 모델은 하나의 모델만 존재하기 때문에 시각화를 통해 어떤 피쳐가 중요하게 작용했는지 확인 가능합니다. 하지만 random forest나 gradient boosting model 같은 경우 여러개의 결정트리를 사용하기 때문에 모든 결정트리를 시각화해서 확인하기 어렵습니다. 그렇기 때문에 변수별로 각 결정트리의 손실함수를 최소화 하는데 얼마나 중요하게 작용했는지를 계산해서 시각화 하는 방법이 주로 사용됩니다. 그림 7-5는 피쳐 중요도를 확인하는 코드 예제입니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img05.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-5 피쳐 중요도 확인 예제(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
</div>
<div class="section" id="gradient-boosting-machine-gbm">
<h2>7.2 Gradient Boosting Machine (GBM)<a class="headerlink" href="#gradient-boosting-machine-gbm" title="Permalink to this headline">¶</a></h2>
<p>Gradient Boosting Machine은 정형 데이터에서 가장 좋은 성능을 내는 결정트리 기반 앙상블 알고리즘입니다.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>정형 데이터에서는 GBM 알고리즘이 우세를 보이며 비정형 데이터에는 딥러닝 알고리즘이 우세를 보입니다.</p>
</div>
<p>GBM은 random forest보다 일찍 등장했습니다. 마찬가지로 ramdom forest를 제안한 UC Berkeley의 Leo Breiman 교수가 1997년에 boosting을 이용한 손실함수 최적화 아이디어를 제안했습니다. 해당 논문에 기반해서 1999년에 Stanford의 Jerome Friedman 교수가 Gradient Boosting Machine 알고리즘을 발표합니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img06.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-6 Jerome Friedman 교수(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>GBM은 결정트리를 순차적으로 학습을 합니다. 첫번째 결정트리를 학습시키고, 해당 트리의 오차를 줄이는 방향으로 두번째 결정트리를 학습시킵니다. 이런식으로 N번째 트리까지 학습시키는 방법이 boosting 학습방법입니다. 이러한 boosting 방법은 개별 결정트리의 bias를 효과적으로 감소시켜 성능을 향상시킵니다.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Element of Statistical Learning 10장에 이론적인 내용이 상세히 서술돼있습니다.</p>
</div>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img07.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-7 GBM 알고리즘(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>위 그림은 GBM의 학습 과정을 도식화한 것입니다. 첫번째 결정트리의 오차인 <code class="docutils literal notranslate"><span class="pre">r1</span></code>이 두번째 트리의 종속변수가 되며, 두번째 트리의 오차인 <code class="docutils literal notranslate"><span class="pre">r2</span></code>가 세번째 트리의 종속변수가 되는 방식으로 학습합니다.</p>
</div>
<div class="section" id="xgboost-vs-lightgbm">
<h2>7.3 XGBoost vs LightGBM<a class="headerlink" href="#xgboost-vs-lightgbm" title="Permalink to this headline">¶</a></h2>
<p>GBM을 구현할 때는 XGBoost 또는 LightGBM 라이브러리를 주로 활용합니다. XGBoost는 현재 Carnegie Mellon University에 있는 Tianqi Chen 교수가 2011년에 박사학위 과정 때 만든 라이브러리 입니다. LightGBM은 Microsoft Asia에 있는 팀이 개발한 라이브러리 입니다. LightGBM은 2017년에 발표가 되면서 빠르게 확산이 된 라이브러리입니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img08.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-8 XGBoost와 LightGBM 로고(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>해당 라이브러리들은 출시 당시 현존했던 다른 구현 방법에 비해 빨랐기 때문에 주목을 받았습니다. XGBoost는 출시될 당시 scikit-learn에서 제공하는 GBM과 R에서 제공하는 gbm 라이브러리에 비해 적게는 2~3배, 많게는 10배까지 빨랐습니다. 단순히 빠를 뿐만 아니라 성능도 다른 GBM 라이브러리 보다 좋았기 때문에 많은 호응을 받았습니다. 2017년에 LightGBM이 등장하면서 XGBoost보다 빠르게 작동했고 성능도 조금 더 높았습니다. 그래서 2017년도 부터는 캐글의 상위 랭커들이 LightGBM을 많이 사용하기도 했습니다.</p>
<p>2020년에 실시한 설문조사에 의하면 XGBoost를 가장 많이 사용하며 그 다음으로 LightGBM 라이브러리를 많이 사용합니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img09.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-9 2020년에 실시한 커뮤니티 설문조사(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>또한 벤치마킹 테스트 결과를 확인해보면 cpu를 사용할 때 데이터의 개수가 10만개 정도일 때는 xgboost가 빠르지만 데이터 개수가 1백만개가 넘어가면 lightgbm가 더 빠른것을 확인할 수 있습니다. 속도 뿐만 아니라 lightgbm이 auc 성능 또한 가장 높은 것을 확인할 수 있습니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img10.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-10 cpu와 gpu에서 GBM 알고리즘 성능 비교(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>XGBoost 라이브러리가 사용은 많이 되지만 대회에서는 LightGBM이 성능이 잘 나오는 경우가 많으므로 이번 장에서는 LightGBM 실습을 진행해보도록 하겠습니다.</p>
<p>LightGBM 구현 코드는 아래와 같습니다.</p>
<p><img alt="" src="https://github.com/kaggler-tv/dku-kaggle-class/blob/master/course-website/imgs/ch07-img11.jpg?raw=true" /></p>
<ul class="simple">
<li><p>그림 7-11 lightGBM 사용 예제(<a class="reference external" href="https://docs.google.com/presentation/d/1c4mg_b1zYxvZw4UrodwmgJXNZw9nv0u9Mjy_oZ6Lmds/edit?usp=sharing">출처</a>)</p></li>
</ul>
<p>LightGBM의 주요 인자는 아래와 같습니다.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>인자</p></th>
<th class="head"><p>설명</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>objective</p></td>
<td><p>학습의 목적 (binary, multiclass, 등)</p></td>
</tr>
<tr class="row-odd"><td><p>n_estimators</p></td>
<td><p>사용할 결정트리의 개수</p></td>
</tr>
<tr class="row-even"><td><p>num_leaves</p></td>
<td><p>사용할 리프 노드의 개수</p></td>
</tr>
<tr class="row-odd"><td><p>learning_rate</p></td>
<td><p>boosting 학습시 기존 에러에 적용할 가중치</p></td>
</tr>
<tr class="row-even"><td><p>min_child_sample</p></td>
<td><p>리프 노드에 존재해야 하는 최소한의 샘플 수</p></td>
</tr>
<tr class="row-odd"><td><p>subsample</p></td>
<td><p>결정트리 학습 시 사용할 샘플의 개수/비율</p></td>
</tr>
<tr class="row-even"><td><p>subsample_freq</p></td>
<td><p>subsampling을 진행할 단위 횟수</p></td>
</tr>
<tr class="row-odd"><td><p>colsample_bytree</p></td>
<td><p>결정트리 학습 시 사용할 피쳐의 개수/비율</p></td>
</tr>
<tr class="row-even"><td><p>random_state</p></td>
<td><p>재현성을 위한 시드값</p></td>
</tr>
<tr class="row-odd"><td><p>n_jobs</p></td>
<td><p>학습시 사용할 쓰레드의 개수, -1일 경우 사용가능한 모든 쓰레드 사용해 학습</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>표 7-2 lightGBM 주요 인자</p></li>
</ul>
<p>LightGBM에서 제공하는 <code class="docutils literal notranslate"><span class="pre">fit()</span></code>함수에는 학습데이터의 종속변수와 독립변수 뿐만 아니라 검증데이터의 종속변수와 독립변수 또한 입력할 수 있는 <code class="docutils literal notranslate"><span class="pre">eval_set</span></code>인자가 존재합니다. <code class="docutils literal notranslate"><span class="pre">eval_set</span></code>인자와 더불어 <code class="docutils literal notranslate"><span class="pre">eval_metric</span></code>을 명시하면 학습 도중에 검증데이터셋에 대한 평가 지표를 같이 보여줍니다. 또한 <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code>인자는 특정 조건이 만족하면 학습을 조기 중단 시켜주는 역할을 합니다. 예를 들어 10이라고 입력을 하면 10번째마다 <code class="docutils literal notranslate"><span class="pre">eval_metric</span></code>이 향상되는지 확인을 합니다. 향상이 안된다면 학습을 조기 종료합니다. <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>에 신경쓸 필요 없이 <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code>에 의해서 학습이 조기 종료되기 때문에 상당히 유용한 인자입니다.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>learning_rate에 따라 early_stopping_rounds 조정이 가능합니다. 0.01 정도의 낮은 learning_rate인 경우 eval_metric가 monotonic하게 감소하기 때문에 early_stopping_rounds는 10정도로 설정해도 무관합니다.</p>
<p>early_stopping_rounds를 크게 주는 경우는 learning_rate값이 높을 때 입니다. learning_rate가 높으면 eval_metric가 진동(oscillate)을 하며 수렴하기 때문에 early_stopping_rounds를 충분히 큰 값으로 줄 필요가 있습니다.</p>
</div>
<p>실습 단계에서 random forest와 lightgbm 알고리즘을 직접 실행해보면서 익혀보시길 바랍니다.</p>
</div>
<div class="section" id="id1">
<h2>7.4 참고자료<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/tutorial/">Scikit-learn 튜토리얼 페이지</a></p>
<ul>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#random-forests">Random Forests</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting">Gradient Boosting</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/">LightGBM 홈페이지</a></p>
<ul>
<li><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">LightGBM Parameters</a></p></li>
<li><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier">LightGBM Scikit-Learn API</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://xgboost.readthedocs.io/en/latest/index.html">XGBoost 홈페이지</a></p></li>
<li><p>ESL 2판 (<a class="reference external" href="https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12_toc.pdf">pdf</a>)</p>
<ul>
<li><p>Chapter 10: Boosting and Additive Trees</p></li>
<li><p>Chapter 15: Random Forest</p></li>
</ul>
</li>
</ul>
<p>Random forest와 GBM의 이론적인 배경이 궁금하시다면 The Elements of Statistical Learning (ESL)의 10장과 15장을 참고하시길 바랍니다.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="07-rf-lgb-intro.html" title="previous page">7. Random Forest, GBM</a>
    <a class='right-next' id="next-link" href="07-rf.html" title="next page">Random Forest 실습</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Kaggler-TV<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            <div class="row_footer"> Website organized by <a href="https://github.com/SDSTony">Sungjin Ahn</a> </div>
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-154415912-2', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>